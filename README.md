# 1. Selective Hearing

This page provides a list of references described in the following paper:


```
Selective Hearing: A Machine Listening Perspective

@inproceedings{CanoLukashevich_MMSP19,
address = {Kuala Lumpur, Malaysia},
author = {Cano, Estefan\'{i} and Lukashevich, Hanna},
booktitle = {Proceedings of the IEEE 21st International Worshop on Multimedia Signal Processing (MMSP)},
title = {{Selective Hearing: A Machine Listening Perspective}},
year = {2019}
}
```

You can download a .bib file with all the references in the paper [here](./MMSP19_SelectiveHearing.bib). 

Below you can find more detailed information about the references and resources.


# Sound Source Detection and Classification

## Sound Events [[18]](https://trepo.tuni.fi//handle/10024/116599)
* [[18]](https://trepo.tuni.fi//handle/10024/116599) Detection and Classification of Acoustic Scenes and Events (DCASE) 
[[website]](http://dcase.community/)
* [[19]](http://dcase.community/documents/workshop2018/proceedings/DCASE2018Workshop_Serizel_22.pdf) Large-scale weakly labeled semi-supervised sound event detection in domestic environments 
[[website]](http://dcase.community/challenge2018/task-large-scale-weakly-labeled-semi-supervised-sound-event-detection)
* [[20]](http://dcase.community/documents/challenge2018/technical_reports/DCASE2018_Lu_19.pdf)  Mean Teacher Convolution System for DCASE 2018 Task 4 
* [[21]](https://ieeexplore.ieee.org/abstract/document/7472917) Recurrent neural networks for polyphonic sound event detection in real life recordings
[[preprint]](http://www.cs.tut.fi/sgn/arg/music/tuomasv/parascandolo-icassp2016.pdf)
* [[22]](https://arxiv.org/abs/1805.03647) End-to-End Polyphonic Sound Event Detection Using Convolutional Recurrent Neural Networks with Learned Time-Frequency Representation Input


![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Noisy Labels`
* [[23]](https://ieeexplore.ieee.org/document/8461975) Large-Scale Weakly Supervised Audio Classification Using Gated Convolutional Neural Network 
[[preprint]](http://personal.ee.surrey.ac.uk/Personal/W.Wang/papers/XuKWP_ICASSP_2018.pdf)
* [[24]](https://ieeexplore.ieee.org/abstract/document/6685834) Classification in the Presence of Label Noise: A Survey
* [[25]](https://ieeexplore.ieee.org/document/8683158) Learning Sound Event Classifiers from Web Audio with Noisy Labels [[preprint]](https://arxiv.org/abs/1901.01189)[[code]](https://github.com/edufonseca/icassp19)
* [[26]](http://dcase.community/documents/challenge2018/technical_reports/DCASE2018_Dorfer_999.pdf) Training General-Purpose Audio Tagging Networks with Noisy Labels and Iterative Self-Verification [[code]](https://github.com/CPJKU/dcase_task2)

![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Joint optimization`
* [[27]](https://ieeexplore.ieee.org/abstract/document/8567942) Sound Event Localization and Detection of Overlapping Sources Using Convolutional Recurrent Neural Networks [[preprint]](https://arxiv.org/abs/1807.00129)

## Speech
![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Voice Activity Detection`
* [[28]](https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1151.pdfn) Joint Learning Using Denoising Variational Autoencoders for Voice Activity Detection
* [[29]](https://ieeexplore.ieee.org/document/6637694) Real-life voice activity detection with {LSTM} Recurrent Neural Networks and an application to Hollywood movies [[preprint]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.364.4084&rep=rep1&type=pdf)
* [[30]](https://pdfs.semanticscholar.org/31c7/4962122ba5fe1c469101b5bc2ae6d88c9c18.pdf) Feature Learning with Raw-Waveform CLDNNs for Voice Activity Detectio

![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Speaker Recognition`
* [[31]](https://ieeexplore.ieee.org/abstract/document/7178885)Advances in deep neural network approaches to speaker recognition

![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Robustness`
* [[32]](https://ieeexplore.ieee.org/document/8461375) X-Vectors: Robust {DNN} Embeddings for Speaker Recognition [[preprint]](https://www.danielpovey.com/files/2018_icassp_xvectors.pdf) [[code]](https://github.com/kaldi-asr/kaldi/tree/master/egs/sre16/v2) [[models]](http://kaldi-asr.org/models/m3)
* [[33]](https://pdfs.semanticscholar.org/dae7/c5e90bbe1538192d85282757068fef79fafa.pdf?_ga=2.97114969.795981087.1569225783-1727351385.1568271670) How to train your speaker embeddings extractor
* [[34]](https://arxiv.org/pdf/1605.01635.pdf) The IBM Speaker Recognition System: Recent Advances and Error Analysis

## Music 
![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Instrument Classification`
* [[35]](https://ieeexplore.ieee.org/document/7755799) Deep Convolutional Neural Networks for Predominant Instrument Recognition in Polyphonic Music [[preprint]](https://arxiv.org/pdf/1605.09507.pdf)
* [[36]](https://arxiv.org/abs/1605.06644) Deep convolutional networks on the pitch spiral for musical instrument recognition

![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Activity Detection`
* [[37]]
* [[38]]

# 2. Sound Source Localization
# 3. Sound Source Separation
# 4. Active Noise Control (ANC)
# 5. Sound Source Enhancement



